# -*- coding: utf-8 -*-
"""Understanding-the-VGG16-architecture.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bD-E6HAzrgMWPtsCnK_lVuog83G6qZTv
"""

import torchvision
import torch.nn as nn
import torch
import torch.nn.functional as F
# The models package has various pretrained models
from torchvision import transforms,models,datasets
!pip install torch_summary
from torchsummary import summary
device = 'cuda' if torch.cuda.is_available() else 'cpu'

device

# Loading weights that were used to classify  images on the imageNet competition
model = models.vgg16(pretrained=True).to(device)

# summary
summary(model, torch.zeros(1,3,224,224));

"""Note that most of the parameters are on the linear layers"""

model

"""In this section we use VGG16 for image classification"""

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from torch import optim
import cv2, glob, numpy as np, pandas as pd
import matplotlib.pyplot as plt
from glob import glob
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset

# download dataset using kaggle key
!pip install -q kaggle
from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!ls ~/.kaggle
!chmod 600 /root/.kaggle/kaggle.json

# download dataset and unzip it
!kaggle datasets download -d tongpython/cat-and-dog
!unzip cat-and-dog.zip

# training and test folders
train_data_dir = 'training_set/training_set'
test_data_dir = 'test_set/test_set'

"""Provide a class that return the input-output pairs for cats and dogs. Only the first 500

While leveraging pre-trained models, it is mandatory to resize, permute, and then normalize images (according to pre-trained model). Images are first scaled to a value between 0 and 1 accross the 3 channels and then normalized to a mean of [0.485, 0.456, 0.406] and standard deviation of [0.229, 0.224, 0.225] across the RGB channels. 
"""

class CatsDogs(Dataset):
  def __init__(self, folder):
    # glob: Returns a list with file paths that matches 
    # the path specified (* == all)
    cats = glob(folder + '/cats/*.jpg')
    dogs = glob(folder + '/dogs/*.jpg')
    self.fpaths = cats[:500] + dogs[:500]  # adding two lists
    # Normalizing according to pre-trained model
    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                         std=[0.229, 0.224, 0.225])
    from random import shuffle, seed
    seed(10);
    # randomize file paths
    shuffle(self.fpaths)
    # list comprehension to generate ground truth
    self.targets = [fpath.split('/')[-1].startswith('dog') for fpath in self.fpaths] # dog=1 & cat=0
  def __len__(self): 
    return len(self.fpaths)
  def __getitem__(self, ix):
    f = self.fpaths[ix] # return the file path
    target = self.targets[ix] # return ground truth
    im = (cv2.imread(f)[:,:,::-1])  # invert channel order to RGB
    im = cv2.resize(im, (224,224))  # resize images
    im = torch.tensor(im/255) # Scale the images (/255) 
    im = im.permute(2,0,1) # permute from (H, W, C) to (C,H,W)
    im = self.normalize(im) # normalize according to pre-trained model 
    # return image and label
    return im.float().to(device), torch.tensor([target]).float().to(device)

# fetch images
data = CatsDogs(train_data_dir)

# sampling an image
im, label = data[1]
plt.imshow(im.permute(1,2,0).cpu())
print(label)

"""define the model, download VGG16, freeze the features module and train using the avgpool and classifier modules"""

# get model
def get_model():
  model = models.vgg16(pretrained=True)
  # freeze all parameters update during backpropagation
  for param in model.parameters():
    param.requires_grad = False
  # replace avgpool to 1x1 instead of 7x7 so the output will be 
  # batch_size x 512 x 1 x 1
  # AdaptiveAvgPool2d automatically computes the kernel size to have 
  # a constant 1x1 output size so a image of any size can be input
  model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))
  # flatten output of avgpool (512), connect to 128 units, activation ...
  model.classifier = nn.Sequential(nn.Flatten(),
                                   nn.Linear(512, 128),
                                   nn.ReLU(),
                                   nn.Dropout(0.2),
                                   nn.Linear(128, 1),
                                   nn.Sigmoid())
  # loss function
  loss_fn = nn.BCELoss()
  optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)
  return model.to(device), loss_fn, optimizer

"""Note that parameters were frozen then avgpool & linear layers were replaced"""

!pip install torch_summary
from torchsummary import summary
model, criterion, optimizer = get_model()
summary(model, torch.zeros(1,3,224,224))

"""Now we will train on a batch and calculate accuracy"""

def train_batch(x, y, model, opt, loss_fn):
  """Train on a batch of data"""
  model.train()
  prediction = model(x)
  batch_loss = loss_fn(prediction, y)
  batch_loss.backward()
  optimizer.step()
  optimizer.zero_grad()
  return batch_loss.item()

# calculate accuracy on a batch
@torch.no_grad()
def accuracy(x, y, model):
  model.eval()
  prediction = model(x)
  is_correct = (prediction > 0.5) == y
  return is_correct.cpu().numpy().tolist()

# function to fetch the dataloaders
def get_data():
  train = CatsDogs(train_data_dir)
  trn_dl = DataLoader(train, batch_size=32, shuffle=True, drop_last = True)
  val = CatsDogs(test_data_dir)
  val_dl = DataLoader(val, batch_size=32, shuffle=True, drop_last = True)
  return trn_dl, val_dl

# initialize get_data and get_model functions
trn_dl, val_dl = get_data()
model, loss_fn, optimizer = get_model()

# train the model over increasing epochs
train_losses, train_accuracies = [], []
val_accuracies = []
for epoch in range(20):
  print(f" epoch {epoch + 1}/20")
  train_epoch_losses, train_epoch_accuracies = [], []
  val_epoch_accuracies = []

  for ix, batch in enumerate(iter(trn_dl)):
      x, y = batch
      batch_loss = train_batch(x, y, model, optimizer, loss_fn)
      train_epoch_losses.append(batch_loss) 
  train_epoch_loss = np.array(train_epoch_losses).mean()

  for ix, batch in enumerate(iter(trn_dl)):
      x, y = batch
      is_correct = accuracy(x, y, model)
      train_epoch_accuracies.extend(is_correct)
  train_epoch_accuracy = np.mean(train_epoch_accuracies)

  for ix, batch in enumerate(iter(val_dl)):
      x, y = batch
      val_is_correct = accuracy(x, y, model)
      val_epoch_accuracies.extend(val_is_correct)
  val_epoch_accuracy = np.mean(val_epoch_accuracies)

  train_losses.append(train_epoch_loss)
  train_accuracies.append(train_epoch_accuracy)
  val_accuracies.append(val_epoch_accuracy)

# Commented out IPython magic to ensure Python compatibility.
# plot training and test accuracy
epochs = np.arange(20)+1
import matplotlib.ticker as mtick
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
# %matplotlib inline
plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')
plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))
plt.title('Training and validation accuracy with VGG16 \nand 1K training data points')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.ylim(0.95,1)
plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) 
plt.legend()
plt.grid('off')
plt.show()