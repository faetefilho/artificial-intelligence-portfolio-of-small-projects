{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v1'\n",
    "env = gym.make(environment_name, render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:12.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        #env.render()\n",
    "        plt.imshow(env.render())\n",
    "        # delay next frame\n",
    "        # plt.pause(0.01)\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00984981, -0.02225065, -0.00449731,  0.00148475], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of action space\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample action\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of observation space, box means it's a continuous space\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1456046e+00,  1.7625645e+37, -4.0356222e-01,  3.2757615e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample observation\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state, reward, done, trucated, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ecdc0f8490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = env.render()\n",
    "# plot the image\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RL model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\\logs\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('training', 'logs')\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets recreate the envionment\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tinho\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# wrap the environment, so it's compatible with the stable baselines code\n",
    "# vectorized environments allow to easily multiprocess training\n",
    "env = DummyVecEnv([lambda: env]) # solve this warning later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)\n",
    "# MLpPolicy is a multi-layer perceptron policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PPO in module stable_baselines3.ppo.ppo:\n",
      "\n",
      "class PPO(stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm)\n",
      " |  PPO(policy: Union[str, Type[stable_baselines3.common.policies.ActorCriticPolicy]], env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv, str], learning_rate: Union[float, Callable[[float], float]] = 0.0003, n_steps: int = 2048, batch_size: int = 64, n_epochs: int = 10, gamma: float = 0.99, gae_lambda: float = 0.95, clip_range: Union[float, Callable[[float], float]] = 0.2, clip_range_vf: Union[NoneType, float, Callable[[float], float]] = None, normalize_advantage: bool = True, ent_coef: float = 0.0, vf_coef: float = 0.5, max_grad_norm: float = 0.5, use_sde: bool = False, sde_sample_freq: int = -1, target_kl: Optional[float] = None, stats_window_size: int = 100, tensorboard_log: Optional[str] = None, policy_kwargs: Optional[Dict[str, Any]] = None, verbose: int = 0, seed: Optional[int] = None, device: Union[torch.device, str] = 'auto', _init_setup_model: bool = True)\n",
      " |  \n",
      " |  Proximal Policy Optimization algorithm (PPO) (clip version)\n",
      " |  \n",
      " |  Paper: https://arxiv.org/abs/1707.06347\n",
      " |  Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\n",
      " |  https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n",
      " |  Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\n",
      " |  \n",
      " |  Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\n",
      " |  \n",
      " |  :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
      " |  :param env: The environment to learn from (if registered in Gym, can be str)\n",
      " |  :param learning_rate: The learning rate, it can be a function\n",
      " |      of the current progress remaining (from 1 to 0)\n",
      " |  :param n_steps: The number of steps to run for each environment per update\n",
      " |      (i.e. rollout buffer size is n_steps * n_envs where n_envs is number of environment copies running in parallel)\n",
      " |      NOTE: n_steps * n_envs must be greater than 1 (because of the advantage normalization)\n",
      " |      See https://github.com/pytorch/pytorch/issues/29372\n",
      " |  :param batch_size: Minibatch size\n",
      " |  :param n_epochs: Number of epoch when optimizing the surrogate loss\n",
      " |  :param gamma: Discount factor\n",
      " |  :param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
      " |  :param clip_range: Clipping parameter, it can be a function of the current progress\n",
      " |      remaining (from 1 to 0).\n",
      " |  :param clip_range_vf: Clipping parameter for the value function,\n",
      " |      it can be a function of the current progress remaining (from 1 to 0).\n",
      " |      This is a parameter specific to the OpenAI implementation. If None is passed (default),\n",
      " |      no clipping will be done on the value function.\n",
      " |      IMPORTANT: this clipping depends on the reward scaling.\n",
      " |  :param normalize_advantage: Whether to normalize or not the advantage\n",
      " |  :param ent_coef: Entropy coefficient for the loss calculation\n",
      " |  :param vf_coef: Value function coefficient for the loss calculation\n",
      " |  :param max_grad_norm: The maximum value for the gradient clipping\n",
      " |  :param use_sde: Whether to use generalized State Dependent Exploration (gSDE)\n",
      " |      instead of action noise exploration (default: False)\n",
      " |  :param sde_sample_freq: Sample a new noise matrix every n steps when using gSDE\n",
      " |      Default: -1 (only sample at the beginning of the rollout)\n",
      " |  :param target_kl: Limit the KL divergence between updates,\n",
      " |      because the clipping is not enough to prevent large update\n",
      " |      see issue #213 (cf https://github.com/hill-a/stable-baselines/issues/213)\n",
      " |      By default, there is no limit on the kl div.\n",
      " |  :param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
      " |      the reported success rate, mean episode length, and mean reward over\n",
      " |  :param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
      " |  :param policy_kwargs: additional arguments to be passed to the policy on creation\n",
      " |  :param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
      " |      debug messages\n",
      " |  :param seed: Seed for the pseudo random generators\n",
      " |  :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
      " |      Setting it to auto, the code will be run on the GPU if possible.\n",
      " |  :param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PPO\n",
      " |      stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm\n",
      " |      stable_baselines3.common.base_class.BaseAlgorithm\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, policy: Union[str, Type[stable_baselines3.common.policies.ActorCriticPolicy]], env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv, str], learning_rate: Union[float, Callable[[float], float]] = 0.0003, n_steps: int = 2048, batch_size: int = 64, n_epochs: int = 10, gamma: float = 0.99, gae_lambda: float = 0.95, clip_range: Union[float, Callable[[float], float]] = 0.2, clip_range_vf: Union[NoneType, float, Callable[[float], float]] = None, normalize_advantage: bool = True, ent_coef: float = 0.0, vf_coef: float = 0.5, max_grad_norm: float = 0.5, use_sde: bool = False, sde_sample_freq: int = -1, target_kl: Optional[float] = None, stats_window_size: int = 100, tensorboard_log: Optional[str] = None, policy_kwargs: Optional[Dict[str, Any]] = None, verbose: int = 0, seed: Optional[int] = None, device: Union[torch.device, str] = 'auto', _init_setup_model: bool = True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  learn(self: ~SelfPPO, total_timesteps: int, callback: Union[NoneType, Callable, List[stable_baselines3.common.callbacks.BaseCallback], stable_baselines3.common.callbacks.BaseCallback] = None, log_interval: int = 1, tb_log_name: str = 'PPO', reset_num_timesteps: bool = True, progress_bar: bool = False) -> ~SelfPPO\n",
      " |      Return a trained model.\n",
      " |      \n",
      " |      :param total_timesteps: The total number of samples (env steps) to train on\n",
      " |      :param callback: callback(s) called at every step with state of the algorithm.\n",
      " |      :param log_interval: The number of episodes before logging.\n",
      " |      :param tb_log_name: the name of the run for TensorBoard logging\n",
      " |      :param reset_num_timesteps: whether or not to reset the current timestep number (used in logging)\n",
      " |      :param progress_bar: Display a progress bar using tqdm and rich.\n",
      " |      :return: the trained model\n",
      " |  \n",
      " |  train(self) -> None\n",
      " |      Update policy using the currently gathered rollout buffer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'policy_aliases': typing.ClassVar[typing.Dict[str, ...\n",
      " |  \n",
      " |  policy_aliases = {'CnnPolicy': <class 'stable_baselines3.common.polici...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm:\n",
      " |  \n",
      " |  collect_rollouts(self, env: stable_baselines3.common.vec_env.base_vec_env.VecEnv, callback: stable_baselines3.common.callbacks.BaseCallback, rollout_buffer: stable_baselines3.common.buffers.RolloutBuffer, n_rollout_steps: int) -> bool\n",
      " |      Collect experiences using the current policy and fill a ``RolloutBuffer``.\n",
      " |      The term rollout here refers to the model-free notion and should not\n",
      " |      be used with the concept of rollout used in model-based RL or planning.\n",
      " |      \n",
      " |      :param env: The training environment\n",
      " |      :param callback: Callback that will be called at each step\n",
      " |          (and at the beginning and end of the rollout)\n",
      " |      :param rollout_buffer: Buffer to fill with rollouts\n",
      " |      :param n_rollout_steps: Number of experiences to collect per environment\n",
      " |      :return: True if function returned with at least `n_rollout_steps`\n",
      " |          collected, False if callback terminated rollout prematurely.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  get_env(self) -> Optional[stable_baselines3.common.vec_env.base_vec_env.VecEnv]\n",
      " |      Returns the current environment (can be None if not defined).\n",
      " |      \n",
      " |      :return: The current environment\n",
      " |  \n",
      " |  get_parameters(self) -> Dict[str, Dict]\n",
      " |      Return the parameters of the agent. This includes parameters from different networks, e.g.\n",
      " |      critics (value functions) and policies (pi functions).\n",
      " |      \n",
      " |      :return: Mapping of from names of the objects to PyTorch state-dicts.\n",
      " |  \n",
      " |  get_vec_normalize_env(self) -> Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]\n",
      " |      Return the ``VecNormalize`` wrapper of the training env\n",
      " |      if it exists.\n",
      " |      \n",
      " |      :return: The ``VecNormalize`` env.\n",
      " |  \n",
      " |  predict(self, observation: Union[numpy.ndarray, Dict[str, numpy.ndarray]], state: Optional[Tuple[numpy.ndarray, ...]] = None, episode_start: Optional[numpy.ndarray] = None, deterministic: bool = False) -> Tuple[numpy.ndarray, Optional[Tuple[numpy.ndarray, ...]]]\n",
      " |      Get the policy action from an observation (and optional hidden state).\n",
      " |      Includes sugar-coating to handle different observations (e.g. normalizing images).\n",
      " |      \n",
      " |      :param observation: the input observation\n",
      " |      :param state: The last hidden states (can be None, used in recurrent policies)\n",
      " |      :param episode_start: The last masks (can be None, used in recurrent policies)\n",
      " |          this correspond to beginning of episodes,\n",
      " |          where the hidden states of the RNN must be reset.\n",
      " |      :param deterministic: Whether or not to return deterministic actions.\n",
      " |      :return: the model's action and the next hidden state\n",
      " |          (used in recurrent policies)\n",
      " |  \n",
      " |  save(self, path: Union[str, pathlib.Path, io.BufferedIOBase], exclude: Optional[Iterable[str]] = None, include: Optional[Iterable[str]] = None) -> None\n",
      " |      Save all the attributes of the object and the model parameters in a zip-file.\n",
      " |      \n",
      " |      :param path: path to the file where the rl agent should be saved\n",
      " |      :param exclude: name of parameters that should be excluded in addition to the default ones\n",
      " |      :param include: name of parameters that might be excluded but should be included anyway\n",
      " |  \n",
      " |  set_env(self, env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv], force_reset: bool = True) -> None\n",
      " |      Checks the validity of the environment, and if it is coherent, set it as the current environment.\n",
      " |      Furthermore wrap any non vectorized env into a vectorized\n",
      " |      checked parameters:\n",
      " |      - observation_space\n",
      " |      - action_space\n",
      " |      \n",
      " |      :param env: The environment for learning a policy\n",
      " |      :param force_reset: Force call to ``reset()`` before training\n",
      " |          to avoid unexpected behavior.\n",
      " |          See issue https://github.com/DLR-RM/stable-baselines3/issues/597\n",
      " |  \n",
      " |  set_logger(self, logger: stable_baselines3.common.logger.Logger) -> None\n",
      " |      Setter for for logger object.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |        When passing a custom logger object,\n",
      " |        this will overwrite ``tensorboard_log`` and ``verbose`` settings\n",
      " |        passed to the constructor.\n",
      " |  \n",
      " |  set_parameters(self, load_path_or_dict: Union[str, Dict[str, torch.Tensor]], exact_match: bool = True, device: Union[torch.device, str] = 'auto') -> None\n",
      " |      Load parameters from a given zip-file or a nested dictionary containing parameters for\n",
      " |      different modules (see ``get_parameters``).\n",
      " |      \n",
      " |      :param load_path_or_iter: Location of the saved data (path or file-like, see ``save``), or a nested\n",
      " |          dictionary containing nn.Module parameters used by the policy. The dictionary maps\n",
      " |          object names to a state-dictionary returned by ``torch.nn.Module.state_dict()``.\n",
      " |      :param exact_match: If True, the given parameters should include parameters for each\n",
      " |          module and each of their parameters, otherwise raises an Exception. If set to False, this\n",
      " |          can be used to update only specific parameters.\n",
      " |      :param device: Device on which the code should run.\n",
      " |  \n",
      " |  set_random_seed(self, seed: Optional[int] = None) -> None\n",
      " |      Set the seed of the pseudo-random generators\n",
      " |      (python, numpy, pytorch, gym, action_space)\n",
      " |      \n",
      " |      :param seed:\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  load(path: Union[str, pathlib.Path, io.BufferedIOBase], env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv, NoneType] = None, device: Union[torch.device, str] = 'auto', custom_objects: Optional[Dict[str, Any]] = None, print_system_info: bool = False, force_reset: bool = True, **kwargs) -> ~SelfBaseAlgorithm from abc.ABCMeta\n",
      " |      Load the model from a zip-file.\n",
      " |      Warning: ``load`` re-creates the model from scratch, it does not update it in-place!\n",
      " |      For an in-place load use ``set_parameters`` instead.\n",
      " |      \n",
      " |      :param path: path to the file (or a file-like) where to\n",
      " |          load the agent from\n",
      " |      :param env: the new environment to run the loaded model on\n",
      " |          (can be None if you only need prediction from a trained model) has priority over any saved environment\n",
      " |      :param device: Device on which the code should run.\n",
      " |      :param custom_objects: Dictionary of objects to replace\n",
      " |          upon loading. If a variable is present in this dictionary as a\n",
      " |          key, it will not be deserialized and the corresponding item\n",
      " |          will be used instead. Similar to custom_objects in\n",
      " |          ``keras.models.load_model``. Useful when you have an object in\n",
      " |          file that can not be deserialized.\n",
      " |      :param print_system_info: Whether to print system info from the saved model\n",
      " |          and the current system info (useful to debug loading issues)\n",
      " |      :param force_reset: Force call to ``reset()`` before training\n",
      " |          to avoid unexpected behavior.\n",
      " |          See https://github.com/DLR-RM/stable-baselines3/issues/597\n",
      " |      :param kwargs: extra arguments to change the model when loading\n",
      " |      :return: new model instance with loaded parameters\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  logger\n",
      " |      Getter for the logger object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help on PPO\n",
    "help(PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 250  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00870285 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.00701    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.57       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 55.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008524535 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.00945     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094476715 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.633       |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006788654 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073330947 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.597       |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069867685 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 356        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00459921 |\n",
      "|    clip_fraction        | 0.0301     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.573     |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.8       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00824   |\n",
      "|    value_loss           | 63.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011252221 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.571      |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422944 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1ecdc118130>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('training', 'saved-models', 'PPO_Model_CartPole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete model to demonstrate loading\n",
    "del model\n",
    "# load model    \n",
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tinho\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tinho\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500.0, 0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[500.]\n",
      "Episode:2 Score:[246.]\n",
      "Episode:3 Score:[500.]\n",
      "Episode:4 Score:[500.]\n",
      "Episode:5 Score:[500.]\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs) # here we use the model to predict the action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "# close the environment\n",
    "# env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
