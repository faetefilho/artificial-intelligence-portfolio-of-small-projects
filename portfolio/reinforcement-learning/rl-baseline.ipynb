{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v1'\n",
    "env = gym.make(environment_name, render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:23.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        #env.render()\n",
    "        plt.imshow(env.render())\n",
    "        # delay next frame\n",
    "        # plt.pause(0.01)\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00986755, -0.03296834, -0.01475957, -0.03886188], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of action space\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample action\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of observation space, box means it's a continuous space\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.6013787e+00, -2.3965259e+38,  1.2081291e-01,  2.7877513e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample observation\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state, reward, done, trucated, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ecdc0f8490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = env.render()\n",
    "# plot the image\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RL model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\\logs\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('training', 'logs')\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets recreate the envionment\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tinho\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# wrap the environment, so it's compatible with the stable baselines code\n",
    "# vectorized environments allow to easily multiprocess training\n",
    "env = DummyVecEnv([lambda: env]) # solve this warning later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)\n",
    "# MLpPolicy is a multi-layer perceptron policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PPO in module stable_baselines3.ppo.ppo:\n",
      "\n",
      "class PPO(stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm)\n",
      " |  PPO(policy: Union[str, Type[stable_baselines3.common.policies.ActorCriticPolicy]], env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv, str], learning_rate: Union[float, Callable[[float], float]] = 0.0003, n_steps: int = 2048, batch_size: int = 64, n_epochs: int = 10, gamma: float = 0.99, gae_lambda: float = 0.95, clip_range: Union[float, Callable[[float], float]] = 0.2, clip_range_vf: Union[NoneType, float, Callable[[float], float]] = None, normalize_advantage: bool = True, ent_coef: float = 0.0, vf_coef: float = 0.5, max_grad_norm: float = 0.5, use_sde: bool = False, sde_sample_freq: int = -1, target_kl: Optional[float] = None, stats_window_size: int = 100, tensorboard_log: Optional[str] = None, policy_kwargs: Optional[Dict[str, Any]] = None, verbose: int = 0, seed: Optional[int] = None, device: Union[torch.device, str] = 'auto', _init_setup_model: bool = True)\n",
      " |  \n",
      " |  Proximal Policy Optimization algorithm (PPO) (clip version)\n",
      " |  \n",
      " |  Paper: https://arxiv.org/abs/1707.06347\n",
      " |  Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\n",
      " |  https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n",
      " |  Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\n",
      " |  \n",
      " |  Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\n",
      " |  \n",
      " |  :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
      " |  :param env: The environment to learn from (if registered in Gym, can be str)\n",
      " |  :param learning_rate: The learning rate, it can be a function\n",
      " |      of the current progress remaining (from 1 to 0)\n",
      " |  :param n_steps: The number of steps to run for each environment per update\n",
      " |      (i.e. rollout buffer size is n_steps * n_envs where n_envs is number of environment copies running in parallel)\n",
      " |      NOTE: n_steps * n_envs must be greater than 1 (because of the advantage normalization)\n",
      " |      See https://github.com/pytorch/pytorch/issues/29372\n",
      " |  :param batch_size: Minibatch size\n",
      " |  :param n_epochs: Number of epoch when optimizing the surrogate loss\n",
      " |  :param gamma: Discount factor\n",
      " |  :param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
      " |  :param clip_range: Clipping parameter, it can be a function of the current progress\n",
      " |      remaining (from 1 to 0).\n",
      " |  :param clip_range_vf: Clipping parameter for the value function,\n",
      " |      it can be a function of the current progress remaining (from 1 to 0).\n",
      " |      This is a parameter specific to the OpenAI implementation. If None is passed (default),\n",
      " |      no clipping will be done on the value function.\n",
      " |      IMPORTANT: this clipping depends on the reward scaling.\n",
      " |  :param normalize_advantage: Whether to normalize or not the advantage\n",
      " |  :param ent_coef: Entropy coefficient for the loss calculation\n",
      " |  :param vf_coef: Value function coefficient for the loss calculation\n",
      " |  :param max_grad_norm: The maximum value for the gradient clipping\n",
      " |  :param use_sde: Whether to use generalized State Dependent Exploration (gSDE)\n",
      " |      instead of action noise exploration (default: False)\n",
      " |  :param sde_sample_freq: Sample a new noise matrix every n steps when using gSDE\n",
      " |      Default: -1 (only sample at the beginning of the rollout)\n",
      " |  :param target_kl: Limit the KL divergence between updates,\n",
      " |      because the clipping is not enough to prevent large update\n",
      " |      see issue #213 (cf https://github.com/hill-a/stable-baselines/issues/213)\n",
      " |      By default, there is no limit on the kl div.\n",
      " |  :param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
      " |      the reported success rate, mean episode length, and mean reward over\n",
      " |  :param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
      " |  :param policy_kwargs: additional arguments to be passed to the policy on creation\n",
      " |  :param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
      " |      debug messages\n",
      " |  :param seed: Seed for the pseudo random generators\n",
      " |  :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
      " |      Setting it to auto, the code will be run on the GPU if possible.\n",
      " |  :param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PPO\n",
      " |      stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm\n",
      " |      stable_baselines3.common.base_class.BaseAlgorithm\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, policy: Union[str, Type[stable_baselines3.common.policies.ActorCriticPolicy]], env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv, str], learning_rate: Union[float, Callable[[float], float]] = 0.0003, n_steps: int = 2048, batch_size: int = 64, n_epochs: int = 10, gamma: float = 0.99, gae_lambda: float = 0.95, clip_range: Union[float, Callable[[float], float]] = 0.2, clip_range_vf: Union[NoneType, float, Callable[[float], float]] = None, normalize_advantage: bool = True, ent_coef: float = 0.0, vf_coef: float = 0.5, max_grad_norm: float = 0.5, use_sde: bool = False, sde_sample_freq: int = -1, target_kl: Optional[float] = None, stats_window_size: int = 100, tensorboard_log: Optional[str] = None, policy_kwargs: Optional[Dict[str, Any]] = None, verbose: int = 0, seed: Optional[int] = None, device: Union[torch.device, str] = 'auto', _init_setup_model: bool = True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  learn(self: ~SelfPPO, total_timesteps: int, callback: Union[NoneType, Callable, List[stable_baselines3.common.callbacks.BaseCallback], stable_baselines3.common.callbacks.BaseCallback] = None, log_interval: int = 1, tb_log_name: str = 'PPO', reset_num_timesteps: bool = True, progress_bar: bool = False) -> ~SelfPPO\n",
      " |      Return a trained model.\n",
      " |      \n",
      " |      :param total_timesteps: The total number of samples (env steps) to train on\n",
      " |      :param callback: callback(s) called at every step with state of the algorithm.\n",
      " |      :param log_interval: The number of episodes before logging.\n",
      " |      :param tb_log_name: the name of the run for TensorBoard logging\n",
      " |      :param reset_num_timesteps: whether or not to reset the current timestep number (used in logging)\n",
      " |      :param progress_bar: Display a progress bar using tqdm and rich.\n",
      " |      :return: the trained model\n",
      " |  \n",
      " |  train(self) -> None\n",
      " |      Update policy using the currently gathered rollout buffer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'policy_aliases': typing.ClassVar[typing.Dict[str, ...\n",
      " |  \n",
      " |  policy_aliases = {'CnnPolicy': <class 'stable_baselines3.common.polici...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm:\n",
      " |  \n",
      " |  collect_rollouts(self, env: stable_baselines3.common.vec_env.base_vec_env.VecEnv, callback: stable_baselines3.common.callbacks.BaseCallback, rollout_buffer: stable_baselines3.common.buffers.RolloutBuffer, n_rollout_steps: int) -> bool\n",
      " |      Collect experiences using the current policy and fill a ``RolloutBuffer``.\n",
      " |      The term rollout here refers to the model-free notion and should not\n",
      " |      be used with the concept of rollout used in model-based RL or planning.\n",
      " |      \n",
      " |      :param env: The training environment\n",
      " |      :param callback: Callback that will be called at each step\n",
      " |          (and at the beginning and end of the rollout)\n",
      " |      :param rollout_buffer: Buffer to fill with rollouts\n",
      " |      :param n_rollout_steps: Number of experiences to collect per environment\n",
      " |      :return: True if function returned with at least `n_rollout_steps`\n",
      " |          collected, False if callback terminated rollout prematurely.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  get_env(self) -> Optional[stable_baselines3.common.vec_env.base_vec_env.VecEnv]\n",
      " |      Returns the current environment (can be None if not defined).\n",
      " |      \n",
      " |      :return: The current environment\n",
      " |  \n",
      " |  get_parameters(self) -> Dict[str, Dict]\n",
      " |      Return the parameters of the agent. This includes parameters from different networks, e.g.\n",
      " |      critics (value functions) and policies (pi functions).\n",
      " |      \n",
      " |      :return: Mapping of from names of the objects to PyTorch state-dicts.\n",
      " |  \n",
      " |  get_vec_normalize_env(self) -> Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]\n",
      " |      Return the ``VecNormalize`` wrapper of the training env\n",
      " |      if it exists.\n",
      " |      \n",
      " |      :return: The ``VecNormalize`` env.\n",
      " |  \n",
      " |  predict(self, observation: Union[numpy.ndarray, Dict[str, numpy.ndarray]], state: Optional[Tuple[numpy.ndarray, ...]] = None, episode_start: Optional[numpy.ndarray] = None, deterministic: bool = False) -> Tuple[numpy.ndarray, Optional[Tuple[numpy.ndarray, ...]]]\n",
      " |      Get the policy action from an observation (and optional hidden state).\n",
      " |      Includes sugar-coating to handle different observations (e.g. normalizing images).\n",
      " |      \n",
      " |      :param observation: the input observation\n",
      " |      :param state: The last hidden states (can be None, used in recurrent policies)\n",
      " |      :param episode_start: The last masks (can be None, used in recurrent policies)\n",
      " |          this correspond to beginning of episodes,\n",
      " |          where the hidden states of the RNN must be reset.\n",
      " |      :param deterministic: Whether or not to return deterministic actions.\n",
      " |      :return: the model's action and the next hidden state\n",
      " |          (used in recurrent policies)\n",
      " |  \n",
      " |  save(self, path: Union[str, pathlib.Path, io.BufferedIOBase], exclude: Optional[Iterable[str]] = None, include: Optional[Iterable[str]] = None) -> None\n",
      " |      Save all the attributes of the object and the model parameters in a zip-file.\n",
      " |      \n",
      " |      :param path: path to the file where the rl agent should be saved\n",
      " |      :param exclude: name of parameters that should be excluded in addition to the default ones\n",
      " |      :param include: name of parameters that might be excluded but should be included anyway\n",
      " |  \n",
      " |  set_env(self, env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv], force_reset: bool = True) -> None\n",
      " |      Checks the validity of the environment, and if it is coherent, set it as the current environment.\n",
      " |      Furthermore wrap any non vectorized env into a vectorized\n",
      " |      checked parameters:\n",
      " |      - observation_space\n",
      " |      - action_space\n",
      " |      \n",
      " |      :param env: The environment for learning a policy\n",
      " |      :param force_reset: Force call to ``reset()`` before training\n",
      " |          to avoid unexpected behavior.\n",
      " |          See issue https://github.com/DLR-RM/stable-baselines3/issues/597\n",
      " |  \n",
      " |  set_logger(self, logger: stable_baselines3.common.logger.Logger) -> None\n",
      " |      Setter for for logger object.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |        When passing a custom logger object,\n",
      " |        this will overwrite ``tensorboard_log`` and ``verbose`` settings\n",
      " |        passed to the constructor.\n",
      " |  \n",
      " |  set_parameters(self, load_path_or_dict: Union[str, Dict[str, torch.Tensor]], exact_match: bool = True, device: Union[torch.device, str] = 'auto') -> None\n",
      " |      Load parameters from a given zip-file or a nested dictionary containing parameters for\n",
      " |      different modules (see ``get_parameters``).\n",
      " |      \n",
      " |      :param load_path_or_iter: Location of the saved data (path or file-like, see ``save``), or a nested\n",
      " |          dictionary containing nn.Module parameters used by the policy. The dictionary maps\n",
      " |          object names to a state-dictionary returned by ``torch.nn.Module.state_dict()``.\n",
      " |      :param exact_match: If True, the given parameters should include parameters for each\n",
      " |          module and each of their parameters, otherwise raises an Exception. If set to False, this\n",
      " |          can be used to update only specific parameters.\n",
      " |      :param device: Device on which the code should run.\n",
      " |  \n",
      " |  set_random_seed(self, seed: Optional[int] = None) -> None\n",
      " |      Set the seed of the pseudo-random generators\n",
      " |      (python, numpy, pytorch, gym, action_space)\n",
      " |      \n",
      " |      :param seed:\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  load(path: Union[str, pathlib.Path, io.BufferedIOBase], env: Union[gymnasium.core.Env, stable_baselines3.common.vec_env.base_vec_env.VecEnv, NoneType] = None, device: Union[torch.device, str] = 'auto', custom_objects: Optional[Dict[str, Any]] = None, print_system_info: bool = False, force_reset: bool = True, **kwargs) -> ~SelfBaseAlgorithm from abc.ABCMeta\n",
      " |      Load the model from a zip-file.\n",
      " |      Warning: ``load`` re-creates the model from scratch, it does not update it in-place!\n",
      " |      For an in-place load use ``set_parameters`` instead.\n",
      " |      \n",
      " |      :param path: path to the file (or a file-like) where to\n",
      " |          load the agent from\n",
      " |      :param env: the new environment to run the loaded model on\n",
      " |          (can be None if you only need prediction from a trained model) has priority over any saved environment\n",
      " |      :param device: Device on which the code should run.\n",
      " |      :param custom_objects: Dictionary of objects to replace\n",
      " |          upon loading. If a variable is present in this dictionary as a\n",
      " |          key, it will not be deserialized and the corresponding item\n",
      " |          will be used instead. Similar to custom_objects in\n",
      " |          ``keras.models.load_model``. Useful when you have an object in\n",
      " |          file that can not be deserialized.\n",
      " |      :param print_system_info: Whether to print system info from the saved model\n",
      " |          and the current system info (useful to debug loading issues)\n",
      " |      :param force_reset: Force call to ``reset()`` before training\n",
      " |          to avoid unexpected behavior.\n",
      " |          See https://github.com/DLR-RM/stable-baselines3/issues/597\n",
      " |      :param kwargs: extra arguments to change the model when loading\n",
      " |      :return: new model instance with loaded parameters\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  logger\n",
      " |      Getter for the logger object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from stable_baselines3.common.base_class.BaseAlgorithm:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help on PPO\n",
    "help(PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 37   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009469858 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00476     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.76        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009610366 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.0749      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009825832 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007433787 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.604      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073353453 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    value_loss           | 64.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008644178 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004780106 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012677374 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.99        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 169          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070911692 |\n",
      "|    clip_fraction        | 0.0851       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.63         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1b981fe48b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('training', 'saved-models', 'PPO_Model_CartPole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete model to demonstrate loading\n",
    "del model\n",
    "# load model    \n",
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tinho\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tinho\\anaconda3\\envs\\gpu-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500.0, 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[500.]\n",
      "Episode:2 Score:[246.]\n",
      "Episode:3 Score:[500.]\n",
      "Episode:4 Score:[500.]\n",
      "Episode:5 Score:[500.]\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs) # here we use the model to predict the action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "# close the environment\n",
    "# env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
